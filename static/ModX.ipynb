{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryabbrj/flask-front/blob/main/ModX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": 3.0293430767166755e+38
      },
      "source": [
        "# Gradio Demo: image_mod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sc-VJ5KYXlfu",
      "metadata": {
        "id": "sc-VJ5KYXlfu"
      },
      "source": [
        "# Pre-Requesite, always run before initating the gardio app!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dkf3rLUR0dcy",
      "metadata": {
        "id": "Dkf3rLUR0dcy"
      },
      "outputs": [],
      "source": [
        "#install gradio library for the ui\n",
        "!pip install -q gradio\n",
        "\n",
        "#install transformers to include pipeline to import and run pretrained image-to-text model.\n",
        "!pip install transformers\n",
        "\n",
        "#ignore model warnings from logging to the console.\n",
        "import warnings,logging\n",
        "warnings.simplefilter('ignore')\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "#mport pipeline \n",
        "from transformers import pipeline\n",
        "\n",
        "#import gradio to begin wrapping ui to the function model.\n",
        "import gradio as gr\n",
        "\n",
        "#import pretrained model and its weights to the predict funtion [this is an optional step that may help speed up prediction by caching the weights to the ml platform. this only logs the prediction to the console, and thus the prediction is not entirely useful in application.]\n",
        "cap = pipeline('image-to-text')\n",
        "pipe = pipeline(\"text-classification\")\n",
        "\n",
        "#uncomment and pass any url/path to the var img and invoke function to predict the caption.\n",
        "\n",
        "#url = 'https://cdn.pixabay.com/photo/2023/02/25/12/30/man-7813108_960_720.jpg'\n",
        "#cap(url)\n",
        "\n",
        "\n",
        "\n",
        "#add sentiment analysis to the caption to identify possible suicidal and depression symptoms!!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09EF44J1X00y",
      "metadata": {
        "id": "09EF44J1X00y"
      },
      "source": [
        "# simply model object call that outputs the prediction to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PYobZwlDrC_A",
      "metadata": {
        "id": "PYobZwlDrC_A"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AQGuPii14Bew",
      "metadata": {
        "id": "AQGuPii14Bew"
      },
      "outputs": [],
      "source": [
        "\n",
        "url = 'https://cdn.pixabay.com/photo/2017/09/30/22/18/bloody-rail-2803727_960_720.jpg'\n",
        "lst = cap(url)\n",
        "caption = ' '.join([str(item) for item in lst])\n",
        "senti = pipe(caption[21:-2])\n",
        "sentiment = ' '.join([str(item) for item in senti])\n",
        "print(\"the genreated caption is :\" , caption[20:-2], \". And the sentiment analysis of this caption results as -\" , sentiment[11:-1] , \"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hV_i2bajmWN3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV_i2bajmWN3",
        "outputId": "d309f6e3-45c2-4886-83b6-ee90faa69912"
      },
      "outputs": [],
      "source": [
        "pipe(\"a woman sitting on the ground looking out a window \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nFwn9NwUYEKn",
      "metadata": {
        "id": "nFwn9NwUYEKn"
      },
      "source": [
        "test v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dXT-n-6FPtz",
      "metadata": {
        "id": "7dXT-n-6FPtz"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": \"I like you. I love you\",\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpucW6nSPpOb",
      "metadata": {
        "id": "hpucW6nSPpOb"
      },
      "source": [
        "##final commit this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FiO8TQ_a7U7t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "FiO8TQ_a7U7t",
        "outputId": "dcd1d591-d73b-42ec-cb39-845fba7d99dc"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import warnings\n",
        "import logging\n",
        "warnings.simplefilter('ignore')\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "\n",
        "\n",
        "    def sentiment_analysis(shortened):\n",
        "      pipe = pipeline('text-classification')\n",
        "      senti = pipe(shortened)\n",
        "      return senti\n",
        "    caption_string = str(caption)\n",
        "    shortened = caption_string.replace(\"[{'generated_text': '\" , \"The image is of, \")\n",
        "    shortened = shortened.replace(\"'}]\" , \"\")\n",
        "    sentiment = sentiment_analysis(shortened)\n",
        "    sentiment_string = ''.join(str(e) for e in sentiment)\n",
        "    formated_senti = sentiment_string.replace(\"{'label': \", \", The Tone of the image(sentiment) after analysisng the caption is that is it is \")\n",
        "    formated_senti = formated_senti.replace(\"'score': \", \"in nature with an average percentage of \")\n",
        "    output = shortened + formated_senti[0:-2] + '%'\n",
        "    return output\n",
        "\n",
        "\n",
        "input = gr.inputs.Image(\n",
        "    label=\"Upload your Image and wait for 8-12 seconds!\", type='pil', optional=False)\n",
        "output = gr.outputs.Textbox(label=\"Captions\")\n",
        "\n",
        "title = \"Content-Mod API UI \"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=input,\n",
        "    outputs=output,\n",
        "    title=title,\n",
        "\n",
        ")\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WqkbxS6jHLw0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WqkbxS6jHLw0",
        "outputId": "cf6856e2-f067-481a-9282-cf7af9557fdd"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import warnings\n",
        "import requests\n",
        "import logging\n",
        "warnings.simplefilter('ignore')\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "\n",
        "\n",
        "    def query(payload):\n",
        "      API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "      headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "\n",
        "      response = requests.post(API_URL, headers=headers, json=payload)\n",
        "      return response.json()\n",
        "\t\n",
        "    caption_string = str(caption)\n",
        "    sentiment = query({\"inputs\": caption_string,})\n",
        "    sentiment_string = ' '.join(str(e) for e in sentiment)\n",
        "    output = caption_string + sentiment_string\n",
        "    return output\n",
        "\n",
        "\n",
        "predict('https://cdn.pixabay.com/photo/2018/05/25/19/13/human-3429797__340.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kIRgnM34LMth",
      "metadata": {
        "id": "kIRgnM34LMth"
      },
      "source": [
        "#adding sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SaYUuLFiKFEe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SaYUuLFiKFEe",
        "outputId": "1c7c7feb-8ea5-4e41-d45d-d12a76fbc60a"
      },
      "outputs": [],
      "source": [
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "\n",
        "\n",
        "    def sentiment_analysis(shortened):\n",
        "      pipe = pipeline('text-classification')\n",
        "      senti = pipe(shortened)\n",
        "      return senti\n",
        "    caption_string = str(caption)\n",
        "    shortened = caption_string.replace(\"[{'generated_text': '\" , \"the image is of, \")\n",
        "    shortened = shortened.replace(\"'}]\" , \"\")\n",
        "    sentiment = sentiment_analysis(shortened)\n",
        "    sentiment_string = ''.join(str(e) for e in sentiment)\n",
        "    formated_senti = sentiment_string.replace(\"{'label': \", \", The Tone of the image(sentiment) after analysisng the caption is that is it is \")\n",
        "    formated_senti = formated_senti.replace(\"'score': \", \" at an average percentage of \")\n",
        "    output = shortened + formated_senti[0:-2] + '%'\n",
        "    return output\n",
        "\n",
        "\n",
        "predict('https://cdn.pixabay.com/photo/2018/05/25/19/13/human-3429797__340.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PstIZzuIJ1Gn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PstIZzuIJ1Gn",
        "outputId": "b17bed9e-91a2-4dee-9a65-8538ef660863"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline('text-classification')\n",
        "pipe(\"a man with a beard and a hat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sm-9ffDJtYhV",
      "metadata": {
        "id": "sm-9ffDJtYhV"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "import warnings\n",
        "import logging\n",
        "warnings.simplefilter('ignore')\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    genereated_dict = cap(image)\n",
        "\n",
        "    final = str(genereated_dict)\n",
        "    def sentiment_analysis(phrase):\n",
        "      pipe = pipeline('text-classification')\n",
        "      sentiment = pipe(phrase)\n",
        "      return str(senti)\n",
        "    senti = sentiment_analysis(final)\n",
        "    output = final[20:-2]\n",
        "    return output\n",
        "\n",
        "\n",
        "input = gr.inputs.Image(\n",
        "    label=\"Upload your Image and wait for 8-12 seconds!\", type='pil', optional=False)\n",
        "output = gr.outputs.Textbox(label=\"Captions\")\n",
        "\n",
        "title = \"Content ModX UI \"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=input,\n",
        "    theme=\"grass\",\n",
        "    outputs= output,\n",
        "    title=title,\n",
        "\n",
        ")\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BzCWORG2zvdp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzCWORG2zvdp",
        "outputId": "201377ed-5a92-43b9-eb54-ceb73acbc8cf"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline('text-classification')\n",
        "senti = pipe('a woman holding a knife in her hand')\n",
        "print(senti)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "azKT6euZufLe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azKT6euZufLe",
        "outputId": "1c0c19cb-d9bd-4c11-d493-a4ceef30aedb"
      },
      "outputs": [],
      "source": [
        "def tes():\n",
        "\n",
        "  caption = \"this that htei htire the re ithe n ion sa ooo llllll\"\n",
        "  sentiment = \"hjkfdhfjkdhfkhhfkjshfjsh\"\n",
        "  output = \"the genreated caption is :\" , caption[20:-2], \". And the sentiment analysis of this caption results as -\" , sentiment, \"%\"\n",
        "  return output\n",
        "outp = tes()\n",
        "print(tes())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y6Dwi1Du8O6k",
      "metadata": {
        "id": "Y6Dwi1Du8O6k"
      },
      "outputs": [],
      "source": [
        "def caption(image):\n",
        "    img = image\n",
        "    caption = pipeline('image-to-text')\n",
        "    caption(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "input_interface = gr.inputs.Image(type='numpy')\n",
        "output_interface = gr.outputs.Textbox()\n",
        "\n",
        "# Create the Gradio app\n",
        "gr.Interface(caption, inputs=input_interface, outputs=output_interface, title=\"Image Captioning\").launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VNwVLuJDYGSi",
      "metadata": {
        "id": "VNwVLuJDYGSi"
      },
      "source": [
        "test v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qe3KMoM-Qa_c",
      "metadata": {
        "id": "qe3KMoM-Qa_c"
      },
      "outputs": [],
      "source": [
        "def caption(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    captioner = cap(image)\n",
        "    return captioner\n",
        "caption('https://cdn.pixabay.com/photo/2020/01/15/19/44/soldier-4768756__340.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wUIEqmqoYIPk",
      "metadata": {
        "id": "wUIEqmqoYIPk"
      },
      "source": [
        "test v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gzT2SnZcSZMW",
      "metadata": {
        "id": "gzT2SnZcSZMW"
      },
      "outputs": [],
      "source": [
        "def my_function(input_str):\n",
        "    # some code here\n",
        "    output_str = \"This is the output string.\"\n",
        "    return output_str\n",
        "\n",
        "\n",
        "input_text = gr.inputs.Textbox()\n",
        "output_text = gr.outputs.Textbox(label=\"outpppp\")\n",
        "\n",
        "gr.Interface(fn=my_function, inputs=input_text, outputs=output_text).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kaSF9ooqU7p9",
      "metadata": {
        "id": "kaSF9ooqU7p9"
      },
      "outputs": [],
      "source": [
        "def caption(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    captioner = cap(image)\n",
        "    return captioner[0]\n",
        "\n",
        "op = gr.outputs.Textbox(label=\"outpppp\")\n",
        "demo = gr.Interface(caption, gr.Image(), outputs=op, flagging_options=[\"accurate👌\", \"just okay👍\", \"wrong🚫\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gWzi_KaDmakV",
      "metadata": {
        "id": "gWzi_KaDmakV"
      },
      "source": [
        "## **finalised code!! do not editttt!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ejdBbhYEYMyZ",
      "metadata": {
        "id": "ejdBbhYEYMyZ"
      },
      "source": [
        "#  This is the stable gradio application code, this requires the pre-requesite setion to be run beforehand to run sucessfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fmPBqbCmWsVr",
      "metadata": {
        "id": "fmPBqbCmWsVr"
      },
      "outputs": [],
      "source": [
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "    return caption\n",
        "\n",
        "\n",
        "input = gr.inputs.Image(label=\"Upload your Image\", type = 'pil', optional=False)\n",
        "output = gr.outputs.Textbox(label=\"Captions\")\n",
        "\n",
        "title = \"Content ModX UI \"\n",
        "\n",
        "interface = gr.Interface(\n",
        "        fn=predict,\n",
        "        inputs = input,\n",
        "        theme=\"grass\",\n",
        "        outputs=output,\n",
        "        title=title,\n",
        "        flagging_options=[\"correct\", \"just okay\", \"wrong\"],\n",
        "\n",
        "    )\n",
        "interface.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gDc0Cj1SYdjs",
      "metadata": {
        "id": "gDc0Cj1SYdjs"
      },
      "source": [
        "test v6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ofAS2h6oeNuR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofAS2h6oeNuR",
        "outputId": "b519364d-159d-4421-d90e-07e0f6db3f04"
      },
      "outputs": [],
      "source": [
        "b4 = \"[{'generated_text': 'a soldier in uniform is holding a gun '}]\"\n",
        "print(b4)\n",
        "xafter  = b4[21:-4] \n",
        "\n",
        "print(xafter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "slzrYOI5Tn6_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slzrYOI5Tn6_",
        "outputId": "cefdf814-ebf7-41d9-db23-adbb08b7f037"
      },
      "outputs": [],
      "source": [
        "b4 = \"[{'generated_text': 'a soldier in uniform is holding a gun '}]\"\n",
        "print(b4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RbibrfdOnRIJ",
      "metadata": {
        "id": "RbibrfdOnRIJ"
      },
      "source": [
        "refining ouput to remove labels, to help tidy up generated caption\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T60wbRcXgFro",
      "metadata": {
        "id": "T60wbRcXgFro"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def my_function():\n",
        "    x = \"mkdsmopvmmd Hello, world! vdvd\"\n",
        "    return x\n",
        "\n",
        "def trim_string(string, trim_start, trim_end):\n",
        "    return string[trim_start:-trim_end]\n",
        "\n",
        "trim_start = 3  # Number of characters to trim from the beginning\n",
        "trim_end = 2  # Number of characters to trim from the end\n",
        "\n",
        "my_string = my_function()\n",
        "trimmed_string = trim_string(my_string, trim_start, trim_end)\n",
        "\n",
        "gr.Interface(\n",
        "    lambda: trimmed_string,\n",
        "    inputs=[],\n",
        "    outputs=gr.outputs.Textbox(),\n",
        ").launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wUs9188CpuWj",
      "metadata": {
        "id": "wUs9188CpuWj"
      },
      "source": [
        "version 8, might fall asleep have to get it done by then!!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1D5NJoToZrk",
      "metadata": {
        "id": "h1D5NJoToZrk"
      },
      "outputs": [],
      "source": [
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "    fcap = refine(caption)\n",
        "    return fcap\n",
        "\n",
        "def refine(caption):\n",
        "    fcapp = caption[21:-4]\n",
        "    return fcapp \n",
        "\n",
        "input = gr.inputs.Image(label=\"Upload your Image\", type = 'pil', optional=False)\n",
        "output = gr.outputs.Textbox(label=\"Captions\")\n",
        "\n",
        "title = \"Image Captioning \"\n",
        "\n",
        "interface = gr.Interface(\n",
        "        fn=predict,\n",
        "        inputs = input,\n",
        "        theme=\"grass\",\n",
        "        outputs=output,\n",
        "        title=title,\n",
        "    )\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8r5CD-t-YkIu",
      "metadata": {
        "id": "8r5CD-t-YkIu"
      },
      "source": [
        "adding flagging and evaluation tools to help with model refining and logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MMmNMNkrqWok",
      "metadata": {
        "id": "MMmNMNkrqWok"
      },
      "outputs": [],
      "source": [
        "#this is a copy of the working stable v5 code, but with added flagging capabilities.\n",
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "    return caption\n",
        "\n",
        "\n",
        "input = gr.inputs.Image(label=\"Upload your Image\", type = 'pil', optional=False)\n",
        "output = gr.outputs.Textbox(label=\"Captions\")\n",
        "\n",
        "title = \"Image Captioning \"\n",
        "\n",
        "interface = gr.Interface(\n",
        "        fn=predict,\n",
        "        inputs = input,\n",
        "        theme=\"grass\",\n",
        "        outputs=output,\n",
        "        title=title,\n",
        "    )\n",
        "interface.launch(debug= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TKGKj-NsZn-O",
      "metadata": {
        "id": "TKGKj-NsZn-O"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def sentence_builder(quantity, animal, countries, place, activity_list, morning):\n",
        "    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    sentence_builder,\n",
        "    [\n",
        "        gr.Slider(1, 3, value=4, label=\"Count\", info=\"Choose betwen 2 and 20\"),\n",
        "        gr.Dropdown(\n",
        "            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n",
        "        ),\n",
        "        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n",
        "        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n",
        "        gr.Dropdown(\n",
        "            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n",
        "        ),\n",
        "        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n",
        "    ],\n",
        "    \"text\",\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gG-rd9fD2X6d",
      "metadata": {
        "id": "gG-rd9fD2X6d"
      },
      "source": [
        "# ***test place***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RLvi9pYyuclW",
      "metadata": {
        "id": "RLvi9pYyuclW"
      },
      "outputs": [],
      "source": [
        "def predict(image,consent):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "    if consent == 'yes':\n",
        "      \n",
        "    return caption,consent\n",
        "\n",
        "\n",
        "input = gr.inputs.Image(label=\"Upload your Image\", type = 'pil', optional=False)\n",
        "consent =gr.Radio([\"yes\", \"no\"], label=\"like to contribute?\", info= \"if the image used here is not a personal image, and if you'd like to help refine the model by contributing this image to its training dataset, please choose yes below. thank you 😍?\")\n",
        "\n",
        "output = gr.outputs.Textbox(label=\"Captions\")\n",
        "\n",
        "title = \"Content ModX UI \"\n",
        "\n",
        "interface = gr.Interface(\n",
        "        fn=predict,\n",
        "        inputs = [input, consent],\n",
        "        theme=\"grass\",\n",
        "        outputs=output,\n",
        "        title=title,\n",
        "        flagging_options=[\"correct\", \"just okay\", \"wrong\"],\n",
        "\n",
        "    )\n",
        "interface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kPhu-LEOITLw",
      "metadata": {
        "id": "kPhu-LEOITLw"
      },
      "source": [
        "logging onto csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dNuczmc5DiI",
      "metadata": {
        "id": "4dNuczmc5DiI"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "a = 3\n",
        "if a == 3:\n",
        "  gr.CSVLogger(\"works\")\n",
        "\n",
        "else:\n",
        "  gr.CSVLogger(\"no\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fcXL5l7ZHPp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fcXL5l7ZHPp",
        "outputId": "2360259c-c33b-44fd-e851-c64418918114"
      },
      "outputs": [],
      "source": [
        "def predict(image):\n",
        "    cap = pipeline('image-to-text')\n",
        "    caption = cap(image)\n",
        "\n",
        "    output = str(caption)\n",
        "    print(type(output))\n",
        "    return output[21:-4]\n",
        "\n",
        "\n",
        "predict(\"https://64.media.tumblr.com/dd8c1817a6e4d9973b14f31cf9e57830/tumblr_pqzhecaQbO1tawn8uo1_1280.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dsp2H5mZFq4C",
      "metadata": {
        "id": "dsp2H5mZFq4C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
